@article{Darling2010,
    author = {Darling, Aaron E. AND Mau, Bob AND Perna, Nicole T.},
    journal = {PLoS ONE},
    publisher = {Public Library of Science},
    title = "{progressiveMauve: Multiple Genome Alignment with Gene Gain, Loss and Rearrangement}",
    year = {2010},
    month = {06},
    volume = {5},
    url = {http://dx.doi.org/10.1371%2Fjournal.pone.0011147},
    pages = {e11147},
    abstract = {<sec>
<title>Background</title>
<p>Multiple genome alignment remains a challenging problem. Effects of recombination including rearrangement, segmental duplication, gain, and loss can create a mosaic pattern of homology even among closely related organisms.</p>
</sec><sec>
<title>Methodology/Principal Findings</title>
<p>We describe a new method to align two or more genomes that have undergone rearrangements due to recombination and substantial amounts of segmental gain and loss (flux). We demonstrate that the new method can accurately align regions conserved in some, but not all, of the genomes, an important case not handled by our previous work. The method uses a novel alignment objective score called a sum-of-pairs breakpoint score, which facilitates accurate detection of rearrangement breakpoints when genomes have unequal gene content. We also apply a probabilistic alignment filtering method to remove erroneous alignments of unrelated sequences, which are commonly observed in other genome alignment methods. We describe new metrics for quantifying genome alignment accuracy which measure the quality of rearrangement breakpoint predictions and indel predictions. The new genome alignment algorithm demonstrates high accuracy in situations where genomes have undergone biologically feasible amounts of genome rearrangement, segmental gain and loss. We apply the new algorithm to a set of 23 genomes from the genera <italic>Escherichia</italic>, <italic>Shigella</italic>, and <italic>Salmonella</italic>. Analysis of whole-genome multiple alignments allows us to extend the previously defined concepts of core- and pan-genomes to include not only annotated genes, but also non-coding regions with potential regulatory roles. The 23 enterobacteria have an estimated core-genome of 2.46Mbp conserved among all taxa and a pan-genome of 15.2Mbp. We document substantial population-level variability among these organisms driven by segmental gain and loss. Interestingly, much variability lies in intergenic regions, suggesting that the Enterobacteriacae may exhibit regulatory divergence.</p>
</sec><sec>
<title>Conclusions</title>
<p>The multiple genome alignments generated by our software provide a platform for comparative genomic and population genomic studies. Free, open-source software implementing the described genome alignment approach is available from <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="http://gel.ahabs.wisc.edu/mauve" xlink:type="simple">http://gel.ahabs.wisc.edu/mauve</ext-link>.</p>
</sec>},
    number = {6},
    doi = {10.1371/journal.pone.0011147}
}        

@unpublished{Salzberg2011,
author = {Steven L. Salzberg and Adam M. Phillippy and Aleksey Zimin and Daniela Puiu and Tanja Magoc and Sergey Koren and Todd Treangen and Michael C. Schatz and Arthur L. Delcher and Michael Roberts and Guillaume Marçais and Mihai Pop and and James A. Yorke.},
title = "{GAGE: a critical evaluation of genome assemblies and assembly algorithms}",
journal = {Genome Research},
year = {2011}
}

@article{Chaisson2008,
author = {Chaisson, Mark J. and Pevzner, Pavel A.}, 
title = {Short read fragment assembly of bacterial genomes}, 
volume = {18}, 
number = {2}, 
pages = {324-330}, 
year = {2008}, 
doi = {10.1101/gr.7088808}, 
abstract ={In the last year, high-throughput sequencing technologies have progressed from proof-of-concept to production quality. While these methods produce high-quality reads, they have yet to produce reads comparable in length to Sanger-based sequencing. Current fragment assembly algorithms have been implemented and optimized for mate-paired Sanger-based reads, and thus do not perform well on short reads produced by short read technologies. We present a new Eulerian assembler that generates nearly optimal short read assemblies of bacterial genomes and describe an approach to assemble reads in the case of the popular hybrid protocol when short and long Sanger-based reads are combined.}, 
URL = {http://genome.cshlp.org/content/18/2/324.abstract}, 
eprint = {http://genome.cshlp.org/content/18/2/324.full.pdf+html}, 
journal = {Genome Research} 
}

@article{Warren2007,
author = {Warren, René L. and Sutton, Granger G. and Jones, Steven J. M. and Holt, Robert A.}, 
title = {Assembling millions of short DNA sequences using SSAKE}, 
volume = {23}, 
number = {4}, 
pages = {500-501}, 
year = {2007}, 
doi = {10.1093/bioinformatics/btl629}, 
abstract ={Summary: Novel DNA sequencing technologies with the potential for up to three orders magnitude more sequence throughput than conventional Sanger sequencing are emerging. The instrument now available from Solexa Ltd, produces millions of short DNA sequences of 25 nt each. Due to ubiquitous repeats in large genomes and the inability of short sequences to uniquely and unambiguously characterize them, the short read length limits applicability for de novo sequencing. However, given the sequencing depth and the throughput of this instrument, stringent assembly of highly identical sequences can be achieved. We describe SSAKE, a tool for aggressively assembling millions of short nucleotide sequences by progressively searching through a prefix tree for the longest possible overlap between any two sequences. SSAKE is designed to help leverage the information from short sequence reads by stringently assembling them into contiguous sequences that can be used to characterize novel sequencing targets.Availability:http://www.bcgsc.ca/bioinfo/software/ssakeContact:rwarren@bcgsc.ca}, 
URL = {http://bioinformatics.oxfordjournals.org/content/23/4/500.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/23/4/500.full.pdf+html}, 
journal = {Bioinformatics} 
}

@article{Earl2011,
author = {Earl, Dent A. and Bradnam, Keith and St. John, John and Darling, Aaron and Lin, Dawei and Faas, Joseph and Yu, Hung On Ken and Vince, Buffalo and Zerbino, Daniel R. and Diekhans, Mark and Nguyen, Ngan and Nuwantha, Pramila and Sung, Ariyaratne Wing-Kin and Ning, Zemin and Haimel, Matthias and Simpson, Jared T. and Fronseca, Nuno A. and Birol, İnanç and Docking, T. Roderick and Ho, Isaac Y. and Rokhsar, Daniel S and Chikhi, Rayan and Lavenier, Dominique and Chapuis, Guillaume and Naquin, Delphine and Maillet, Nicolas and Schatz, Michael C. and Kelly, David R. and Phillippy, Adam M. and Koren, Sergey and Yang, Shiaw-Pyng and Wu, Wei and Chou, Wen-Chi and Srivastava, Anuj and Shaw, Timothy I. and Ruby, J. Graham and Skewes-Cox, Peter and Betegon, Miguel and Dimon, Michelle T. and Solovyev, Victor and Kosarev, Petr and Vorobyev, Denis and Ramirez-Gonzalez, Ricardo and Leggett, Richard and MacLean, Dan and Xia, Fangfang and Luo, Ruibang and L, Zhenyu and Xie, Yinlong and Liu, Binghang and Gnerre, Sante and MacCallum, Iain and Przybylski, Dariusz and Ribeiro, Filipe J. and Yin, Shuangye and Sharpe, Ted and Hall, Giles and Kersey, Paul J. and Durbin, Richard and Jackman, Shaun D. and Chapman, Jarrod A. and Huang, Xiaoqiu and DeRisi, Joseph L. and Caccamo, Mario and Li, Yingrui and Jaffe, David B. and Green, Richard and Haussler, David and Korf, Ian and Paten, Benedict}, 
title = {Assemblathon 1: A competitive assessment of de novo short read assembly methods}, 
year = {2011}, 
doi = {10.1101/gr.126599.111}, 
abstract ={Low cost short read sequencing technology has revolutionised genomics, though it is only just becoming practical for the high quality de novo assembly of a novel large genome. We describe the Assemblathon 1 competition, which aimed to comprehensively assess the state of the art in de novo assembly methods when applied to current sequencing technologies. In a collaborative effort teams were asked to assemble a simulated Illumina HiSeq dataset of an unknown, simulated diploid genome. A total of 41 assemblies from 17 different groups were received. Novel haplotype aware assessments of coverage, contiguity, structure, base calling and copy number were made. We establish that within this benchmark (1) it is possible to assemble the genome to a high level of coverage and accuracy, and that (2) large differences exist between the assemblies, suggesting room for further improvements in current methods.}, 
URL = {http://genome.cshlp.org/content/early/2011/09/16/gr.126599.111.abstract}, 
eprint = {http://genome.cshlp.org/content/early/2011/09/16/gr.126599.111.full.pdf+html}, 
journal = {Genome Research} 
}

@article{Zerbino2008, title={Velvet: algorithms for de novo short read assembly using de Bruijn graphs.}, volume={18}, url={http://www.ncbi.nlm.nih.gov/pubmed/18349386}, number={5}, journal={Genome Research}, publisher={Cold Spring Harbor Lab}, author={Zerbino, Daniel R and Birney, Ewan}, year={2008}, pages={821--9}}

@article{Koren2011,
author = {Koren, Sergey and Treangen, Todd J and Pop, Mihai}, 
title = {Bambus 2: Scaffolding Metagenomes}, 
year = {2011}, 
doi = {10.1093/bioinformatics/btr520}, 
abstract ={Motivation: Sequencing projects increasingly target samples from non-clonal sources. In particular, metagenomics has enabled scientists to begin to characterize the structure of microbial communities. The software tools developed for assembling and analyzing sequencing data for clonal organisms are, however, unable to adequately process data derived from non-clonal sources.Results: We present a new scaffolder, Bambus 2 to address some of the challenges encountered when analyzing metagenomes. Our approach relies on a combination of a novel method for detecting genomic repeats and algorithms that analyze assembly graphs to identify biologically meaningful genomic variants. We compare our software to current assemblers using simulated and real data. We demonstrate that the repeat detection algorithms have higher sensitivity than current approaches without sacrificing specificity. In metagenomic datasets, the scaffolder avoids false joins between distantly related organisms while obtaining long-range contiguity. Bambus 2 represents a first step towards automated metagenomic assembly.Availability: Bambus 2 is open-source and available from http://amos.sf.net.Contact: mpop@umiacs.umd.edu}, 
URL = {http://bioinformatics.oxfordjournals.org/content/early/2011/09/16/bioinformatics.btr520.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/early/2011/09/16/bioinformatics.btr520.full.pdf+html}, 
journal = {Bioinformatics} 
}

@article{Kozarewa2009, title={Amplification-free Illumina sequencing-library preparation facilitates improved mapping and assembly of (G+C)-biased genomes.}, volume={6}, url={http://www.ncbi.nlm.nih.gov/pubmed/19287394}, number={4}, journal={Nature Methods}, publisher={Nature Publishing Group}, author={Kozarewa, Iwanka and Ning, Zemin and Quail, Michael A and Sanders, Mandy J and Berriman, Matthew and Turner, Daniel J}, year={2009}, pages={291--295}}

@Article{Dayarian2010,
AUTHOR = {Dayarian, Adel and Michael, Todd and Sengupta, Anirvan},
TITLE = {SOPRA: Scaffolding algorithm for paired reads via statistical optimization},
JOURNAL = {BMC Bioinformatics},
VOLUME = {11},
YEAR = {2010},
NUMBER = {1},
PAGES = {345},
URL = {http://www.biomedcentral.com/1471-2105/11/345},
DOI = {10.1186/1471-2105-11-345},
PubMedID = {20576136},
ISSN = {1471-2105},
ABSTRACT = {BACKGROUND:High throughput sequencing (HTS) platforms produce gigabases of short read (<100 bp) data per run. While these short reads are adequate for resequencing applications, de novo assembly of moderate size genomes from such reads remains a significant challenge. These limitations could be partially overcome by utilizing mate pair technology, which provides pairs of short reads separated by a known distance along the genome.RESULTS:We have developed SOPRA, a tool designed to exploit the mate pair/paired-end information for assembly of short reads. The main focus of the algorithm is selecting a sufficiently large subset of simultaneously satisfiable mate pair constraints to achieve a balance between the size and the quality of the output scaffolds. Scaffold assembly is presented as an optimization problem for variables associated with vertices and with edges of the contig connectivity graph. Vertices of this graph are individual contigs with edges drawn between contigs connected by mate pairs. Similar graph problems have been invoked in the context of shotgun sequencing and scaffold building for previous generation of sequencing projects. However, given the error-prone nature of HTS data and the fundamental limitations from the shortness of the reads, the ad hoc greedy algorithms used in the earlier studies are likely to lead to poor quality results in the current context. SOPRA circumvents this problem by treating all the constraints on equal footing for solving the optimization problem, the solution itself indicating the problematic constraints (chimeric/repetitive contigs, etc.) to be removed. The process of solving and removing of constraints is iterated till one reaches a core set of consistent constraints. For SOLiD sequencer data, SOPRA uses a dynamic programming approach to robustly translate the color-space assembly to base-space. For assessing the quality of an assembly, we report the no-match/mismatch error rate as well as the rates of various rearrangement errors.CONCLUSIONS:Applying SOPRA to real data from bacterial genomes, we were able to assemble contigs into scaffolds of significant length (N50 up to 200 Kb) with very few errors introduced in the process. In general, the methodology presented here will allow better scaffold assemblies of any type of mate pair sequencing data.},
}


@article{Boetzer2011,
author = {Boetzer, Marten and Henkel, Christiaan V. and Jansen, Hans J. and Butler, Derek and Pirovano, Walter}, 
title="{Scaffolding pre-assembled contigs using SSPACE}", 
volume = {27}, 
number = {4}, 
pages = {578-579}, 
year = {2011}, 
doi = {10.1093/bioinformatics/btq683}, 
abstract ={Summary: De novo assembly tools play a main role in reconstructing genomes from next-generation sequencing (NGS) data and usually yield a number of contigs. Using paired-read sequencing data it is possible to assess the order, distance and orientation of contigs and combine them into so-called scaffolds. Although the latter process is a crucial step in finishing genomes, scaffolding algorithms are often built-in functions in de novo assembly tools and cannot be independently controlled. We here present a new tool, called SSPACE, which is a stand-alone scaffolder of pre-assembled contigs using paired-read data. Main features are: a short runtime, multiple library input of paired-end and/or mate pair datasets and possible contig extension with unmapped sequence reads. SSPACE shows promising results on both prokaryote and eukaryote genomic testsets where the amount of initial contigs was reduced by at least 75%.Availability: www.baseclear.com/bioinformatics-tools/.Contact: walter.pirovano@baseclear.comSupplementary information: Supplementary data are available at Bioinformatics online.}, 
URL = {http://bioinformatics.oxfordjournals.org/content/27/4/578.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/27/4/578.full.pdf+html}, 
journal = {Bioinformatics} 
}

@article{Simpson2010,
author = {Simpson, Jared T. and Durbin, Richard}, 
title = {Efficient construction of an assembly string graph using the FM-index}, 
volume = {26}, 
number = {12}, 
pages = {i367-i373}, 
year = {2010}, 
doi = {10.1093/bioinformatics/btq217}, 
abstract ={Motivation: Sequence assembly is a difficult problem whose importance has grown again recently as the cost of sequencing has dramatically dropped. Most new sequence assembly software has started by building a de Bruijn graph, avoiding the overlap-based methods used previously because of the computational cost and complexity of these with very large numbers of short reads. Here, we show how to use suffix array-based methods that have formed the basis of recent very fast sequence mapping algorithms to find overlaps and generate assembly string graphs asymptotically faster than previously described algorithms.Results: Standard overlap assembly methods have time complexity O(N2), where N is the sum of the lengths of the reads. We use the Ferragina–Manzini index (FM-index) derived from the Burrows–Wheeler transform to find overlaps of length at least τ among a set of reads. As well as an approach that finds all overlaps then implements transitive reduction to produce a string graph, we show how to output directly only the irreducible overlaps, significantly shrinking memory requirements and reducing compute time to O(N), independent of depth. Overlap-based assembly methods naturally handle mixed length read sets, including capillary reads or long reads promised by the third generation sequencing technologies. The algorithms we present here pave the way for overlap-based assembly approaches to be developed that scale to whole vertebrate genome de novo assembly.Contact: js18@sanger.ac.uk}, 
URL = {http://bioinformatics.oxfordjournals.org/content/26/12/i367.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/26/12/i367.full.pdf+html}, 
journal = {Bioinformatics} 
}

@article{Peng2010, title={IDBA - A Practical Iterative de Bruijn Graph De Novo Assembler}, volume={6044}, url={http://www.springerlink.com/index/622866948LH233G7.pdf}, journal={Computer}, publisher={Springer}, author={Peng, Yu and Leung, Henry and Yiu, S M and Chin, Francis Y L}, year={2010}, pages={426--440}}

<<<<<<< .mine
@article{Haas2004,
author = {Haas, Brian J. and Delcher, Arthur L. and Wortman, Jennifer R. and Salzberg, Steven L.}, 
title = {DAGchainer: a tool for mining segmental genome duplications and synteny}, 
volume = {20}, 
number = {18}, 
pages = {3643-3646}, 
year = {2004}, 
doi = {10.1093/bioinformatics/bth397}, 
abstract ={Summary: Given the positions of protein-coding genes along genomic sequence and probability values for protein alignments between genes, DAGchainer identifies chains of gene pairs sharing conserved order between genomic regions, by identifying paths through a directed acyclic graph (DAG). These chains of collinear gene pairs can represent segmentally duplicated regions and genes within a single genome or syntenic regions between related genomes. Automated mining of the Arabidopsis genome for segmental duplications illustrates the use of DAGchainer.}, 
URL = {http://bioinformatics.oxfordjournals.org/content/20/18/3643.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/20/18/3643.full.pdf+html}, 
journal = {Bioinformatics} 
}

@article{Calabrese2003,
author = {Calabrese, Peter P. and Chakravarty, Sugata and Vision, Todd J.}, 
title = {Fast identification and statistical evaluation of segmental homologies in comparative maps}, 
volume = {19}, 
number = {suppl 1}, 
pages = {i74-i80}, 
year = {2003}, 
doi = {10.1093/bioinformatics/btg1008}, 
abstract ={Motivation: Chromosomal segments that share common ancestry, either through
genomic duplication or species divergence, are said to be
segmental homologs of one another. Their identification
allows researchers to leverage knowledge of model organisms for
use in other systems and is of value for studies of genome
evolution. However, identification and statistical evaluation of
segmental homologies can be a challenge when the segments are
highly diverged.Results: We describe a flexible dynamic programming algorithm for the
identification of segments having multiple homologous features. We
model the probability of observing putative segmental homologies
by chance and incorporate our findings into the parameterization
of the algorithm and the statistical evaluation of its output.
Combined, these findings allow segmental homologies to be
identified in comparisons within and between genomic maps in a
rigorous, rapid, and automated fashion.Availability: http://www.bio.unc.edu/faculty/vision/lab/Contact: tjv@bio.unc.eduKeywords: homology, comparative maps, synteny, genome evolution
        
      }, 
URL = {http://bioinformatics.oxfordjournals.org/content/19/suppl_1/i74.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/19/suppl_1/i74.full.pdf+html}, 
journal = {Bioinformatics} 
}

@Article{Kelley2010,
AUTHOR = {Kelley, David and Schatz, Michael and Salzberg, Steven},
TITLE = {Quake: quality-aware detection and correction of sequencing errors},
JOURNAL = {Genome Biology},
VOLUME = {11},
YEAR = {2010},
NUMBER = {11},
PAGES = {R116},
URL = {http://genomebiology.com/2010/11/11/R116},
DOI = {10.1186/gb-2010-11-11-r116},
PubMedID = {21114842},
ISSN = {1465-6906},
ABSTRACT = {We introduce Quake, a program to detect and correct errors in DNA sequencing reads. Using a maximum likelihood approach incorporating quality values and nucleotide specific miscall rates, Quake achieves the highest accuracy on realistically simulated reads. We further demonstrate substantial improvements in de novo assembly and SNP detection after using Quake. Quake can be used for any size project, including more than one billion human reads, and is freely available as open source software from http://www.cbcb.umd.edu/software/quake webcite.},
}


@article{Kao2011,
author = {Kao, Wei-Chun and Chan, Andrew H. and Song, Yun S.}, 
title = {ECHO: A reference-free short-read error correction algorithm}, 
volume = {21}, 
number = {7}, 
pages = {1181-1192}, 
year = {2011}, 
doi = {10.1101/gr.111351.110}, 
abstract ={Developing accurate, scalable algorithms to improve data quality is an important computational challenge associated with recent advances in high-throughput sequencing technology. In this study, a novel error-correction algorithm, called ECHO, is introduced for correcting base-call errors in short-reads, without the need of a reference genome. Unlike most previous methods, ECHO does not require the user to specify parameters of which optimal values are typically unknown a priori. ECHO automatically sets the parameters in the assumed model and estimates error characteristics specific to each sequencing run, while maintaining a running time that is within the range of practical use. ECHO is based on a probabilistic model and is able to assign a quality score to each corrected base. Furthermore, it explicitly models heterozygosity in diploid genomes and provides a reference-free method for detecting bases that originated from heterozygous sites. On both real and simulated data, ECHO is able to improve the accuracy of previous error-correction methods by several folds to an order of magnitude, depending on the sequence coverage depth and the position in the read. The improvement is most pronounced toward the end of the read, where previous methods become noticeably less effective. Using a whole-genome yeast data set, it is demonstrated here that ECHO is capable of coping with nonuniform coverage. Also, it is shown that using ECHO to perform error correction as a preprocessing step considerably facilitates de novo assembly, particularly in the case of low-to-moderate sequence coverage depth.}, 
URL = {http://genome.cshlp.org/content/21/7/1181.abstract}, 
eprint = {http://genome.cshlp.org/content/21/7/1181.full.pdf+html}, 
journal = {Genome Research} 
}

@Article{Kircher2009,
AUTHOR = {Kircher, Martin and Stenzel, Udo and Kelso, Janet},
TITLE = {Improved base calling for the Illumina Genome Analyzer using machine learning strategies},
JOURNAL = {Genome Biology},
VOLUME = {10},
YEAR = {2009},
NUMBER = {8},
PAGES = {R83},
URL = {http://genomebiology.com/2009/10/8/R83},
DOI = {10.1186/gb-2009-10-8-r83},
PubMedID = {19682367},
ISSN = {1465-6906},
ABSTRACT = {The Illumina Genome Analyzer generates millions of short sequencing reads. We present Ibis (Improved base identification system), an accurate, fast and easy-to-use base caller that significantly reduces the error rate and increases the output of usable reads. Ibis is faster and more robust with respect to chemistry and technology than other publicly available packages. Ibis is freely available under the GPL from http://bioinf.eva.mpg.de/Ibis/ webcite.},
}

@article{BayesCall,
author = {Kao, Wei-Chun and Stevens, Kristian and Song, Yun S}, 
title = {BayesCall: A model-based basecalling algorithm for high-throughput short-read sequencing}, 
year = {2009}, 
doi = {10.1101/gr.095299.109}, 
abstract ={Extracting sequence information from raw images of fluorescence is the foundation underlying several high-throughput sequencing platforms. Some of the main challenges associated with this technology include reducing the error rate, assigning accurate base-specific quality scores, and reducing the cost of sequencing by increasing the throughput per run.  To demonstrate how computational advancement can help to meet these challenges, a novel model-based basecalling algorithm BayesCall is introduced for the Illumina sequencing platform.  Being founded on the tools of statistical learning, BayesCall is flexible enough to incorporate various features of the sequencing process.  In particular, it can easily incorporate time-dependent parameters and model residual effects. This new approach significantly improves the accuracy over Illumina's basecaller Bustard, particularly in the later cycles of a sequencing run.  For 76-cycle data on a standard viral sample PhiX174,  BayesCall improves Bustard's average per-base error rate by about 52%.  The probability of observing each base can be readily computed in BayesCall, and this probability can be transformed into a useful base-specific quality score with a high discrimination ability.   A detailed study of BayesCall's performance is presented here.}, 
URL = {http://genome.cshlp.org/content/early/2009/08/06/gr.095299.109.abstract}, 
eprint = {http://genome.cshlp.org/content/early/2009/08/06/gr.095299.109.full.pdf+html}, 
journal = {Genome Research} 
}

@article{Lassmann2009,
author = {Lassmann, Timo and Hayashizaki, Yoshihide and Daub, Carsten O.}, 
title = {TagDust—a program to eliminate artifacts from next generation sequencing data}, 
volume = {25}, 
number = {21}, 
pages = {2839-2840}, 
year = {2009}, 
doi = {10.1093/bioinformatics/btp527}, 
abstract ={Motivation: Next-generation parallel sequencing technologies produce large quantities of short sequence reads. Due to experimental procedures various types of artifacts are commonly sequenced alongside the targeted RNA or DNA sequences. Identification of such artifacts is important during the development of novel sequencing assays and for the downstream analysis of the sequenced libraries.Results: Here we present TagDust, a program identifying artifactual sequences in large sequencing runs. Given a user-defined cutoff for the false discovery rate, TagDust identifies all reads explainable by combinations and partial matches to known sequences used during library preparation. We demonstrate the quality of our method on sequencing runs performed on Illumina's Genome Analyzer platform.Availability: Executables and documentation are available from http://genome.gsc.riken.jp/osc/english/software/.Contact: timolassmann@gmail.com}, 
URL = {http://bioinformatics.oxfordjournals.org/content/25/21/2839.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/25/21/2839.full.pdf+html}, 
journal = {Bioinformatics} 
}

@article{Yang2010,
author = {Yang, Xiao and Dorman, Karin S. and Aluru, Srinivas}, 
title="{Reptile: representative tiling for short read error correction}", 
volume = {26}, 
number = {20}, 
pages = {2526-2533}, 
year = {2010}, 
doi = {10.1093/bioinformatics/btq468}, 
abstract ={Motivation: Error correction is critical to the success of next-generation sequencing applications, such as resequencing and de novo genome sequencing. It is especially important for high-throughput short-read sequencing, where reads are much shorter and more abundant, and errors more frequent than in traditional Sanger sequencing. Processing massive numbers of short reads with existing error correction methods is both compute and memory intensive, yet the results are far from satisfactory when applied to real datasets.Results: We present a novel approach, termed Reptile, for error correction in short-read data from next-generation sequencing. Reptile works with the spectrum of k-mers from the input reads, and corrects errors by simultaneously examining: (i) Hamming distance-based correction possibilities for potentially erroneous k-mers; and (ii) neighboring k-mers from the same read for correct contextual information. By not needing to store input data, Reptile has the favorable property that it can handle data that does not fit in main memory. In addition to sequence data, Reptile can make use of available quality score information. Our experiments show that Reptile outperforms previous methods in the percentage of errors removed from the data and the accuracy in true base assignment. In addition, a significant reduction in run time and memory usage have been achieved compared with previous methods, making it more practical for short-read error correction when sampling larger genomes.Availability: Reptile is implemented in C++ and is available through the link: http://aluru-sun.ece.iastate.edu/doku.php?id=softwareContact: aluru@iastate.edu}, 
URL = {http://bioinformatics.oxfordjournals.org/content/26/20/2526.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/26/20/2526.full.pdf+html}, 
journal = {Bioinformatics} 
}
@article{Hartman2010,
     author = {Hartman, Amber L. AND Norais, Cédric AND Badger, Jonathan H. AND Delmas, Stéphane AND Haldenby, Sam AND Madupu, Ramana AND Robinson, Jeffrey AND Khouri, Hoda AND Ren, Qinghu AND Lowe, Todd M. AND Maupin-Furlow, Julie AND Pohlschroder, Mecky AND Daniels, Charles AND Pfeiffer, Friedhelm AND Allers, Thorsten AND Eisen, Jonathan A.},
    journal = {PLoS ONE},
    publisher = {Public Library of Science},
    title = "{The Complete Genome Sequence of \textit{Haloferax volcanii} DS2, a Model Archaeon}",
    year = {2010},
    month = {03},
    volume = {5},
    url = {http://dx.doi.org/10.1371%2Fjournal.pone.0009605},
    pages = {e9605},
    abstract = {<sec>
<title>Background</title>
<p><italic>Haloferax volcanii</italic> is an easily culturable moderate halophile that grows on simple defined media, is readily transformable, and has a relatively stable genome. This, in combination with its biochemical and genetic tractability, has made <italic>Hfx. volcanii</italic> a key model organism, not only for the study of halophilicity, but also for archaeal biology in general.</p>
</sec><sec>
<title>Methodology/Principal Findings</title>
<p>We report here the sequencing and analysis of the genome of <italic>Hfx. volcanii</italic> DS2, the type strain of this species. The genome contains a main 2.848 Mb chromosome, three smaller chromosomes pHV1, 3, 4 (85, 438, 636 kb, respectively) and the pHV2 plasmid (6.4 kb).</p>
</sec><sec>
<title>Conclusions/Significance</title>
<p>The completed genome sequence, presented here, provides an invaluable tool for further <italic>in vivo</italic> and <italic>in vitro</italic> studies of <italic>Hfx. volcanii</italic>.</p>
</sec>},
    number = {3},
    doi = {10.1371/journal.pone.0009605}
}        


@article{Treangen2006,
    author = {Treangen, Todd  J.  and Messeguer, Xavier  },
    citeulike-article-id = {885153},
    doi = {10.1186/1471-2105-7-433},
    issn = {1471-2105},
    journal = {BMC Bioinformatics},
    keywords = {alignment genomecomparison genomerearrangement},
    month = {October},
    pages = {433+},
    priority = {2},
    title = "{M-GCAT: Interactively and efficiently constructing large-scale multiple genome comparison frameworks in closely related species}",
    url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve\&db=pubmed\&dopt=Abstract\&list_uids=17022809},
    volume = {7},
    year = {2006}
}

@ARTICLE{mauve,
author = "Darling, Aaron C E and Mau, Bob and Blattner, Frederick R  and Perna, Nicole T",
journal = "Genome Res",
pages = "1394--403",
title = "{Mauve: multiple alignment of conserved genomic sequence with rearrangements}",
volume = "14",
number = "7",
year = 2004,
}


@article{Yancopoulos2005,
    abstract = {MOTIVATION: Finding genomic distance based on gene order is a classic problem in genome rearrangements. Efficient exact algorithms for genomic distances based on inversions and/or translocations have been found but are complicated by special cases, rare in simulations and empirical data. We seek a universal operation underlying a more inclusive set of evolutionary operations and yielding a tractable genomic distance with simple mathematical form. RESULTS: We study a universal double-cut-and-join operation that accounts for inversions, translocations, fissions and fusions, but also produces circular intermediates which can be reabsorbed. The genomic distance, computable in linear time, is given by the number of breakpoints minus the number of cycles (b-c) in the comparison graph of the two genomes; the number of hurdles does not enter into it. Without changing the formula, we can replace generation and re-absorption of a circular intermediate by a generalized transposition, equivalent to a block interchange, with weight two. Our simple algorithm converts one multi-linear chromosome genome to another in the minimum distance.},
    address = {The Feinstein Institute for Medical Research North Shore-LIJ Health System, Manhasset, NY 11030, USA. syancopo@nshs.edu},
    author = {Yancopoulos, S.  and Attie, O.  and Friedberg, R. },
    citeulike-article-id = {735705},
    issn = {1367-4803},
    journal = {Bioinformatics},
    keywords = {genomerearrangement},
    month = {August},
    number = {16},
    pages = {3340--3346},
    priority = {2},
title="{Efficient sorting of genomic permutations by translocation, inversion and block interchange}",
    url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve\&db=pubmed\&dopt=Abstract\&list_uids=15951307},
    volume = {21},
    year = {2005}
}

@inproceedings{Bergeron2006,
   author = {Bergeron, A. and Mixtacki, J. and Stoye, J.},
title="{A Unifying View of Genome Rearrangements}",
  booktitle = {WABI '06: Proceedings of the Sixth International Workshop on Algorithms in Bioinformatics},
  series    = {Lecture Notes in Computer Science},
  volume    = {4175},
  year      = {2006},
  pages     = {163-173},
  ee        = {http://dx.doi.org/10.1007/11851561_16},
  crossref  = {DBLP:conf/wabi/2006},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@proceedings{DBLP:conf/wabi/2006,
  editor    = {Philipp Bucher and
               Bernard M. E. Moret},
  title     = {Algorithms in Bioinformatics, 6th International Workshop,
               WABI 2006, Zurich, Switzerland, September 11-13, 2006, Proceedings},
  booktitle = {WABI},
  publisher = {Springer},
  series    = {Lecture Notes in Computer Science},
  volume    = {4175},
  year      = {2006},
  isbn      = {3-540-39583-0},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}


@article{BLAST,
author = {Altschul, Stephen F. and Madden, Thomas L. and Schäffer, Alejandro A. and Zhang, Jinghui and Zhang, Zheng and Miller, Webb and Lipman, David J.}, 
title = "{Gapped BLAST and PSI-BLAST: a new generation of protein database search programs}", 
volume = {25}, 
number = {17}, 
pages = {3389-3402}, 
year = {1997}, 
doi = {10.1093/nar/25.17.3389}, 
abstract ={The BLAST programs are widely used tools for searching protein and DNA databases for sequence similarities. For protein comparisons, a variety of definitional, algorithmic and statistical refinements described here permits the execution time of the BLAST programs to be decreased substantially while enhancing their sensitivity to weak similarities. A new criterion for triggering the extension of word hits, combined with a new heuristic for generating gapped alignments, yields a gapped BLAST program that runs at approximately three times the speed of the original. In addition, a method is introduced for automatically combining statistically significant alignments produced by BLAST into a position-specific score matrix, and searching the database using this matrix. The resulting Position-Specific Iterated BLAST (PSIBLAST) program runs at approximately the same speed per iteration as gapped BLAST, but in many cases is much more sensitive to weak but biologically relevant sequence similarities. PSI-BLAST is used to uncover several new and interesting members of the BRCT superfamily.}, 
URL = {http://nar.oxfordjournals.org/content/25/17/3389.abstract}, 
eprint = {http://nar.oxfordjournals.org/content/25/17/3389.full.pdf+html}, 
journal = {Nucleic Acids Research} 
}

@Article{bowtie,
AUTHOR = {Langmead, Ben and Trapnell, Cole and Pop, Mihai and Salzberg, Steven},
TITLE = {Ultrafast and memory-efficient alignment of short DNA sequences to the human genome},
JOURNAL = {Genome Biology},
VOLUME = {10},
YEAR = {2009},
NUMBER = {3},
PAGES = {R25},
URL = {http://genomebiology.com/2009/10/3/R25},
DOI = {10.1186/gb-2009-10-3-r25},
PubMedID = {19261174},
ISSN = {1465-6906},
ABSTRACT = {
            Bowtie is an ultrafast, memory-efficient alignment program for aligning short DNA sequence reads to large genomes. For the human genome, Burrows-Wheeler indexing allows Bowtie to align more than 25 million reads per CPU hour with a memory footprint of approximately 1.3 gigabytes. Bowtie extends previous Burrows-Wheeler techniques with a novel quality-aware backtracking algorithm that permits mismatches. Multiple processor cores can be used simultaneously to achieve even greater alignment speeds. Bowtie is open source http://bowtie.cbcb.umd.edu webcite.
      },
}
@article{bwa,
author = {Li, Heng and Durbin, Richard}, 
title="{Fast and accurate short read alignment with Burrows–Wheeler transform}", 
volume = {25}, 
number = {14}, 
pages = {1754-1760}, 
year = {2009}, 
doi = {10.1093/bioinformatics/btp324}, 
abstract ={Motivation: The enormous amount of short reads generated by the new DNA sequencing technologies call for the development of fast and accurate read alignment programs. A first generation of hash table-based methods has been developed, including MAQ, which is accurate, feature rich and fast enough to align short reads from a single individual. However, MAQ does not support gapped alignment for single-end reads, which makes it unsuitable for alignment of longer reads where indels may occur frequently. The speed of MAQ is also a concern when the alignment is scaled up to the resequencing of hundreds of individuals.Results: We implemented Burrows-Wheeler Alignment tool (BWA), a new read alignment package that is based on backward search with Burrows–Wheeler Transform (BWT), to efficiently align short sequencing reads against a large reference sequence such as the human genome, allowing mismatches and gaps. BWA supports both base space reads, e.g. from Illumina sequencing machines, and color space reads from AB SOLiD machines. Evaluations on both simulated and real data suggest that BWA is ∼10–20× faster than MAQ, while achieving similar accuracy. In addition, BWA outputs alignment in the new standard SAM (Sequence Alignment/Map) format. Variant calling and other downstream analyses after the alignment can be achieved with the open source SAMtools software package.Availability: http://maq.sourceforge.netContact: rd@sanger.ac.uk}, 
URL = {http://bioinformatics.oxfordjournals.org/content/25/14/1754.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/25/14/1754.full.pdf+html}, 
journal = {Bioinformatics} 
}


@article{Rissman2009,
author = {Rissman, Anna I. and Mau, Bob and Biehl, Bryan S. and Darling, Aaron E. and Glasner, Jeremy D. and Perna, Nicole T.}, 
title = "{Reordering contigs of draft genomes using the Mauve Aligner}", 
volume = {25}, 
number = {16}, 
pages = {2071-2073}, 
year = {2009}, 
doi = {10.1093/bioinformatics/btp356}, 
abstract ={Summary: Mauve Contig Mover provides a new method for proposing the relative order of contigs that make up a draft genome based on comparison to a complete or draft reference genome. A novel application of the Mauve aligner and viewer provides an automated reordering algorithm coupled with a powerful drill-down display allowing detailed exploration of results.Availability: The software is available for download at http://gel.ahabs.wisc.edu/mauve.Contact: rissman@wisc.eduSupplementary information: Supplementary data are available at Bioinformatics online and http://gel.ahabs.wisc.edu}, 
URL = {http://bioinformatics.oxfordjournals.org/content/25/16/2071.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/25/16/2071.full.pdf+html}, 
journal = {Bioinformatics} 
}

@article{Li2010,
author = {Li, Ruiqiang and Zhu, Hongmei and Ruan, Jue and Qian, Wubin and Fang, Xiaodong and Shi, Zhongbin and Li, Yingrui and Li, Shengting and Shan, Gao and Kristiansen, Karsten and Li, Songgang and Yang, Huanming and Wang, Jian and Wang, Jun}, 
title = {De novo assembly of human genomes with massively parallel short read sequencing}, 
volume = {20}, 
number = {2}, 
pages = {265-272}, 
year = {2010}, 
doi = {10.1101/gr.097261.109}, 
abstract ={Next-generation massively parallel DNA sequencing technologies provide ultrahigh throughput at a substantially lower unit data cost; however, the data are very short read length sequences, making de novo assembly extremely challenging. Here, we describe a novel method for de novo assembly of large genomes from short read sequences. We successfully assembled both the Asian and African human genome sequences, achieving an N50 contig size of 7.4 and 5.9 kilobases (kb) and scaffold of 446.3 and 61.9 kb, respectively. The development of this de novo short read assembly method creates new opportunities for building reference sequences and carrying out accurate analyses of unexplored genomes in a cost-effective way.}, 
URL = {http://genome.cshlp.org/content/20/2/265.abstract}, 
eprint = {http://genome.cshlp.org/content/20/2/265.full.pdf+html}, 
journal = {Genome Research} 
}

@manual{SASSY,
author = {Imelfort, Michael},
title = {The {SaSSY} manual, retrieved from {https://github.com/minillinim/SaSSY/blob/master/SaSSY\_manual.pdf}},
month = {June},
year = {2011},
url = {https://github.com/minillinim/SaSSY/blob/master/SaSSY\_manual.pdf}
}

@article{Ewing1998,
author = {Ewing, Brent and Green, Phil}, 
title = {Base-Calling of Automated Sequencer Traces UsingPhred. II. Error Probabilities}, 
volume = {8}, 
number = {3}, 
pages = {186-194}, 
year = {1998}, 
doi = {10.1101/gr.8.3.186}, 
abstract ={Elimination of the data processing bottleneck in high-throughput sequencing will require both improved accuracy of data processing software and reliable measures of that accuracy. We have developed and implemented in our base-calling program phred the ability to estimate a probability of error for each base-call, as a function of certain parameters computed from the trace data. These error probabilities are shown here to be valid (correspond to actual error rates) and to have high power to discriminate correct base-calls from incorrect ones, for read data collected under several different chemistries and electrophoretic conditions. They play a critical role in our assembly program phrap and our finishing programconsed.
}, 
URL = {http://genome.cshlp.org/content/8/3/186.abstract}, 
eprint = {http://genome.cshlp.org/content/8/3/186.full.pdf+html}, 
journal = {Genome Research} 
}

@article{Gnerre2011,
author = {Gnerre, Sante and MacCallum, Iain and Przybylski, Dariusz and Ribeiro, Filipe J. and Burton, Joshua N. and Walker, Bruce J. and Sharpe, Ted and Hall, Giles and Shea, Terrance P. and Sykes, Sean and Berlin, Aaron M. and Aird, Daniel and Costello, Maura and Daza, Riza and Williams, Louise and Nicol, Robert and Gnirke, Andreas and Nusbaum, Chad and Lander, Eric S. and Jaffe, David B.}, 
title = {High-quality draft assemblies of mammalian genomes from massively parallel sequence data}, 
volume = {108}, 
number = {4}, 
pages = {1513-1518}, 
year = {2011}, 
doi = {10.1073/pnas.1017351108}, 
abstract ={Massively parallel DNA sequencing technologies are revolutionizing genomics by making it possible to generate billions of relatively short (~100-base) sequence reads at very low cost. Whereas such data can be readily used for a wide range of biomedical applications, it has proven difficult to use them to generate high-quality de novo genome assemblies of large, repeat-rich vertebrate genomes. To date, the genome assemblies generated from such data have fallen far short of those obtained with the older (but much more expensive) capillary-based sequencing approach. Here, we report the development of an algorithm for genome assembly, ALLPATHS-LG, and its application to massively parallel DNA sequence data from the human and mouse genomes, generated on the Illumina platform. The resulting draft genome assemblies have good accuracy, short-range contiguity, long-range connectivity, and coverage of the genome. In particular, the base accuracy is high (≥99.95%) and the scaffold sizes (N50 size = 11.5 Mb for human and 7.2 Mb for mouse) approach those obtained with capillary-based sequencing. The combination of improved sequencing technology and improved computational methods should now make it possible to increase dramatically the de novo sequencing of large genomes. The ALLPATHS-LG program is available at http://www.broadinstitute.org/science/programs/genome-biology/crd.}, 
URL = {http://www.pnas.org/content/108/4/1513.abstract}, 
eprint = {http://www.pnas.org/content/108/4/1513.full.pdf+html}, 
journal = {Proceedings of the National Academy of Sciences} 
}
@article{Li01032008,
author = {Li, Ruiqiang and Li, Yingrui and Kristiansen, Karsten and Wang, Jun}, 
title = {SOAP: short oligonucleotide alignment program}, 
volume = {24}, 
number = {5}, 
pages = {713-714}, 
year = {2008}, 
doi = {10.1093/bioinformatics/btn025}, 
abstract ={Summary: We have developed a program SOAP for efficient gapped and ungapped alignment of short oligonucleotides onto reference sequences. The program is designed to handle the huge amounts of short reads generated by parallel sequencing using the new generation Illumina-Solexa sequencing technology. SOAP is compatible with numerous applications, including single-read or pair-end resequencing, small RNA discovery and mRNA tag sequence mapping. SOAP is a command-driven program, which supports multi-threaded parallel computing, and has a batch module for multiple query sets.Availability: http://soap.genomics.org.cnContact: soap@genomics.org.cn}, 
URL = {http://bioinformatics.oxfordjournals.org/content/24/5/713.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/24/5/713.full.pdf+html}, 
journal = {Bioinformatics} 
}
@article{Darling2011,
author = {Darling, Aaron and Tritt, Andrew and Eisen, Jonathan A. and Facciotti, Marc T.}, 
title = {Mauve Assembly Metrics}, 
year = {2011}, 
doi = {10.1093/bioinformatics/btr451}, 
abstract ={Summary: High throughput DNA sequencing technologies have spurred the development of numerous novel methods for genome assembly. With few exceptions, these algorithms are heuristic and require one or more parameters to be manually set by the user. One approach to parameter tuning involves assembling data from an organism with an available high quality reference genome, and measuring assembly accuracy using some metrics.We developed a system to measure assembly quality under several scoring metrics, and to compare assembly quality across a variety of assemblers, sequence data types, and parameter choices. When used in conjunction with training data such as a high quality reference genome and sequence reads from the same organism, our program can be used to manually identify an optimal sequencing and assembly strategy for de novo sequencing of related organisms.Availability: GPL source code and a usage tutorial is at http://ngopt.googlecode.comContact: aarondarling@ucdavis.edu}, 
URL = {http://bioinformatics.oxfordjournals.org/content/early/2011/08/02/bioinformatics.btr451.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/early/2011/08/02/bioinformatics.btr451.full.pdf+html}, 
journal = {Bioinformatics} 
}
@Article{Adey2010,
AUTHOR = {Adey, Andrew and Morrison, Hilary and Asan and Xun, Xu and Kitzman, Jacob and Turner, Emily and Stackhouse, Bethany and MacKenzie, Alexandra and Caruccio, Nicholas and Zhang, Xiuqing and Shendure, Jay},
TITLE = {Rapid, low-input, low-bias construction of shotgun fragment libraries by high-density in vitro transposition},
JOURNAL = {Genome Biology},
VOLUME = {11},
YEAR = {2010},
NUMBER = {12},
PAGES = {R119},
URL = {http://genomebiology.com/content/11/12/R119},
DOI = {10.1186/gb-2010-11-12-r119},
PubMedID = {21143862},
ISSN = {1465-6906},
ABSTRACT = {We characterize and extend a highly efficient method for constructing shotgun fragment libraries in which transposase catalyzes in vitro DNA fragmentation and adaptor incorporation simultaneously. We apply this method to sequencing a human genome and find that coverage biases are comparable to those of conventional protocols. We also extend its capabilities by developing protocols for sub-nanogram library construction, exome capture from 50 ng of input DNA, PCR-free and colony PCR library construction, and 96-plex sample indexing.},
}
@article{DBSCAN, 
title={A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise}, 
volume={96}, url={http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:A+Density-Based+Algorithm+for+Discovering+Clusters+in+Large+Spatial+Databases+with+Noise#0}, 
journal={Computer}, 
publisher={AAAI Press}, 
author={Ester, Martin and Kriegel, Hans-Peter and Sander, Jörg and Xu, Xiaowei}, 
year={1996},
pages={226–231}}

@article{GuptaChen2010,
  author    = {Maya R. Gupta and
               Yihua Chen},
  title     = {Theory and Use of the EM Algorithm},
  journal   = {Foundations and Trends in Signal Processing},
  volume    = {4},
  number    = {3},
  year      = {2010},
  pages     = {223-296},
  ee        = {http://dx.doi.org/10.1561/2000000034},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@conference{AMSTLSC,
author = {Min Deng and Qiliang Liu and Guangqiang Li and Tao Cheng},
editor = {Yaolin Liu and Xinming Tang},
collaboration = {},
title = {An adaptive spatial clustering algorithm based on the minimum spanning tree-like},
publisher = {SPIE},
year = {2009},
journal = {International Symposium on Spatial Analysis, Spatial-Temporal Data Modeling, and Data Mining},
volume = {7492},
number = {1},
eid = {74921Z},
numpages = {9},
pages = {74921Z},
location = {Wuhan, China},
url = {http://link.aip.org/link/?PSI/7492/74921Z/1},
doi = {10.1117/12.838295}
}

@INPROCEEDINGS{STING,
    author = {Wei Wang and Jiong Yang and Richard Muntz},
    title = {STING: A statistical information grid approach to spatial data mining},
    year = {1997},
    pages = {186--195},
    publisher = {Morgan Kaufmann}
}

@article{bambus2,
author = {Koren, Sergey and Treangen, Todd J. and Pop, Mihai}, 
title = {Bambus 2: scaffolding metagenomes}, 
volume = {27}, 
number = {21}, 
pages = {2964-2971}, 
year = {2011}, 
doi = {10.1093/bioinformatics/btr520}, 
abstract ={Motivation: Sequencing projects increasingly target samples from non-clonal sources. In particular, metagenomics has enabled scientists to begin to characterize the structure of microbial communities. The software tools developed for assembling and analyzing sequencing data for clonal organisms are, however, unable to adequately process data derived from non-clonal sources.Results: We present a new scaffolder, Bambus 2, to address some of the challenges encountered when analyzing metagenomes. Our approach relies on a combination of a novel method for detecting genomic repeats and algorithms that analyze assembly graphs to identify biologically meaningful genomic variants. We compare our software to current assemblers using simulated and real data. We demonstrate that the repeat detection algorithms have higher sensitivity than current approaches without sacrificing specificity. In metagenomic datasets, the scaffolder avoids false joins between distantly related organisms while obtaining long-range contiguity. Bambus 2 represents a first step toward automated metagenomic assembly.Availability: Bambus 2 is open source and available from http://amos.sf.net.Contact: mpop@umiacs.umd.eduSupplementary Information: Supplementary data are available at Bioinformatics online.}, 
URL = {http://bioinformatics.oxfordjournals.org/content/27/21/2964.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/27/21/2964.full.pdf+html}, 
journal = {Bioinformatics} 
}
@article{euler-sr,
author = {Chaisson, Mark J. and Pevzner, Pavel A.}, 
title = {Short read fragment assembly of bacterial genomes}, 
volume = {18}, 
number = {2}, 
pages = {324-330}, 
year = {2008}, 
doi = {10.1101/gr.7088808}, 
abstract ={In the last year, high-throughput sequencing technologies have progressed from proof-of-concept to production quality. While these methods produce high-quality reads, they have yet to produce reads comparable in length to Sanger-based sequencing. Current fragment assembly algorithms have been implemented and optimized for mate-paired Sanger-based reads, and thus do not perform well on short reads produced by short read technologies. We present a new Eulerian assembler that generates nearly optimal short read assemblies of bacterial genomes and describe an approach to assemble reads in the case of the popular hybrid protocol when short and long Sanger-based reads are combined.}, 
URL = {http://genome.cshlp.org/content/18/2/324.abstract}, 
eprint = {http://genome.cshlp.org/content/18/2/324.full.pdf+html}, 
journal = {Genome Research} 
}
@Article{ibis,
AUTHOR = {Kircher, Martin and Stenzel, Udo and Kelso, Janet},
TITLE = {Improved base calling for the Illumina Genome Analyzer using machine learning strategies},
JOURNAL = {Genome Biology},
VOLUME = {10},
YEAR = {2009},
NUMBER = {8},
PAGES = {R83},
URL = {http://genomebiology.com/2009/10/8/R83},
DOI = {10.1186/gb-2009-10-8-r83},
PubMedID = {19682367},
ISSN = {1465-6906},
ABSTRACT = {The Illumina Genome Analyzer generates millions of short sequencing reads. We present Ibis (Improved base identification system), an accurate, fast and easy-to-use base caller that significantly reduces the error rate and increases the output of usable reads. Ibis is faster and more robust with respect to chemistry and technology than other publicly available packages. Ibis is freely available under the GPL from http://bioinf.eva.mpg.de/Ibis/ webcite.},
}

@Article{quake,
AUTHOR = {Kelley, David and Schatz, Michael and Salzberg, Steven},
TITLE = {Quake: quality-aware detection and correction of sequencing errors},
JOURNAL = {Genome Biology},
VOLUME = {11},
YEAR = {2010},
NUMBER = {11},
PAGES = {R116},
URL = {http://genomebiology.com/2010/11/11/R116},
DOI = {10.1186/gb-2010-11-11-r116},
PubMedID = {21114842},
ISSN = {1465-6906},
ABSTRACT = {We introduce Quake, a program to detect and correct errors in DNA sequencing reads. Using a maximum likelihood approach incorporating quality values and nucleotide specific miscall rates, Quake achieves the highest accuracy on realistically simulated reads. We further demonstrate substantial improvements in de novo assembly and SNP detection after using Quake. Quake can be used for any size project, including more than one billion human reads, and is freely available as open source software from http://www.cbcb.umd.edu/software/quake webcite.},
}

@article{shrec,
author = {Schröder, Jan and Schröder, Heiko and Puglisi, Simon J. and Sinha, Ranjan and Schmidt, Bertil}, 
title = {SHREC: a short-read error correction method}, 
volume = {25}, 
number = {17}, 
pages = {2157-2163}, 
year = {2009}, 
doi = {10.1093/bioinformatics/btp379}, 
abstract ={Motivation: Second-generation sequencing technologies produce a massive amount of short reads in a single experiment. However, sequencing errors can cause major problems when using this approach for de novo sequencing applications. Moreover, existing error correction methods have been designed and optimized for shotgun sequencing. Therefore, there is an urgent need for the design of fast and accurate computational methods and tools for error correction of large amounts of short read data.Results: We present SHREC, a new algorithm for correcting errors in short-read data that uses a generalized suffix trie on the read data as the underlying data structure. Our results show that the method can identify erroneous reads with sensitivity and specificity of over 99% and 96% for simulated data with error rates of up to 3% as well as for real data. Furthermore, it achieves an error correction accuracy of over 80% for simulated data and over 88% for real data. These results are clearly superior to previously published approaches. SHREC is available as an efficient open-source Java implementation that allows processing of 10 million of short reads on a standard workstation.Availability: SHREC source code in JAVA is freely available at http://www.informatik.uni-kiel.de/∼jasc/Shrec/Contact: jasc@informatik.uni-kiel.de}, 
URL = {http://bioinformatics.oxfordjournals.org/content/25/17/2157.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/25/17/2157.full.pdf+html}, 
journal = {Bioinformatics} 
}
@article{vcake,
author = {Jeck, William R. and Reinhardt, Josephine A. and Baltrus, David A. and Hickenbotham, Matthew T. and Magrini, Vincent and Mardis, Elaine R. and Dangl, Jeffery L. and Jones, Corbin D.}, 
title = {Extending assembly of short DNA sequences to handle error}, 
volume = {23}, 
number = {21}, 
pages = {2942-2944}, 
year = {2007}, 
doi = {10.1093/bioinformatics/btm451}, 
abstract ={Inexpensive de novo genome sequencing, particularly in organisms with small genomes, is now possible using several new sequencing technologies. Some of these technologies such as that from Illumina's Solexa Sequencing, produce high genomic coverage by generating a very large number of small reads (∼30 bp). While prior work shows that partial assembly can be performed by k-mer extension in error-free reads, this algorithm is unsuccessful with the sequencing error rates found in practice. We present VCAKE (Verified Consensus Assembly by K-mer Extension), a modification of simple k-mer extension that overcomes error by using high depth coverage. Though it is a simple modification of a previous approach, we show significant improvements in assembly results on simulated and experimental datasets that include error.Availability: http://152.2.15.114/~labweb/VCAKEContact: william.jeck@gmail.com}, 
URL = {http://bioinformatics.oxfordjournals.org/content/23/21/2942.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/23/21/2942.full.pdf+html}, 
journal = {Bioinformatics} 
}
@Article{SOPRA,
AUTHOR = {Dayarian, Adel and Michael, Todd and Sengupta, Anirvan},
TITLE = {SOPRA: Scaffolding algorithm for paired reads via statistical optimization},
JOURNAL = {BMC Bioinformatics},
VOLUME = {11},
YEAR = {2010},
NUMBER = {1},
PAGES = {345},
URL = {http://www.biomedcentral.com/1471-2105/11/345},
DOI = {10.1186/1471-2105-11-345},
PubMedID = {20576136},
ISSN = {1471-2105},
ABSTRACT = {BACKGROUND:High throughput sequencing (HTS) platforms produce gigabases of short read (<100 bp) data per run. While these short reads are adequate for resequencing applications, de novo assembly of moderate size genomes from such reads remains a significant challenge. These limitations could be partially overcome by utilizing mate pair technology, which provides pairs of short reads separated by a known distance along the genome.RESULTS:We have developed SOPRA, a tool designed to exploit the mate pair/paired-end information for assembly of short reads. The main focus of the algorithm is selecting a sufficiently large subset of simultaneously satisfiable mate pair constraints to achieve a balance between the size and the quality of the output scaffolds. Scaffold assembly is presented as an optimization problem for variables associated with vertices and with edges of the contig connectivity graph. Vertices of this graph are individual contigs with edges drawn between contigs connected by mate pairs. Similar graph problems have been invoked in the context of shotgun sequencing and scaffold building for previous generation of sequencing projects. However, given the error-prone nature of HTS data and the fundamental limitations from the shortness of the reads, the ad hoc greedy algorithms used in the earlier studies are likely to lead to poor quality results in the current context. SOPRA circumvents this problem by treating all the constraints on equal footing for solving the optimization problem, the solution itself indicating the problematic constraints (chimeric/repetitive contigs, etc.) to be removed. The process of solving and removing of constraints is iterated till one reaches a core set of consistent constraints. For SOLiD sequencer data, SOPRA uses a dynamic programming approach to robustly translate the color-space assembly to base-space. For assessing the quality of an assembly, we report the no-match/mismatch error rate as well as the rates of various rearrangement errors.CONCLUSIONS:Applying SOPRA to real data from bacterial genomes, we were able to assemble contigs into scaffolds of significant length (N50 up to 200 Kb) with very few errors introduced in the process. In general, the methodology presented here will allow better scaffold assemblies of any type of mate pair sequencing data.},
}

@article{SVDetect,
author = {Zeitouni, Bruno and Boeva, Valentina and Janoueix-Lerosey, Isabelle and Loeillet, Sophie and Legoix-né, Patricia and Nicolas, Alain and Delattre, Olivier and Barillot, Emmanuel}, 
title = {SVDetect: a tool to identify genomic structural variations from paired-end and mate-pair sequencing data}, 
volume = {26}, 
number = {15}, 
pages = {1895-1896}, 
year = {2010}, 
doi = {10.1093/bioinformatics/btq293}, 
abstract ={Summary: We present SVDetect, a program designed to identify genomic structural variations from paired-end and mate-pair next-generation sequencing data produced by the Illumina GA and ABI SOLiD platforms. Applying both sliding-window and clustering strategies, we use anomalously mapped read pairs provided by current short read aligners to localize genomic rearrangements and classify them according to their type, e.g. large insertions–deletions, inversions, duplications and balanced or unbalanced inter-chromosomal translocations. SVDetect outputs predicted structural variants in various file formats for appropriate graphical visualization.Availability: Source code and sample data are available at http://svdetect.sourceforge.net/Contact: svdetect@curie.frSupplementary information: Supplementary data are available at Bioinformatics online.}, 
URL = {http://bioinformatics.oxfordjournals.org/content/26/15/1895.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/26/15/1895.full.pdf+html}, 
journal = {Bioinformatics} 
}
@Article{BreakDancer,
author="Chen, Ken
and Wallis, John W.
and McLellan, Michael D.
and Larson, David E.
and Kalicki, Joelle M.
and Pohl, Craig S.
and McGrath, Sean D.
and Wendl, Michael C.
and Zhang, Qunyuan
and Locke, Devin P.
and Shi, Xiaoqi
and Fulton, Robert S.
and Ley, Timothy J.
and Wilson, Richard K.
and Ding, Li
and Mardis, Elaine R.",
title="BreakDancer: an algorithm for high-resolution mapping of genomic structural variation",
journal="Nat Meth",
year="2009",
month="Sep",
publisher="Nature Publishing Group",
volume="6",
number="9",
pages="677--681",
issn="1548-7091",
doi="10.1038/nmeth.1363",
url="http://dx.doi.org/10.1038/nmeth.1363"
}

@article{Pop2009,
author = {Pop, Mihai}, 
title = {Genome assembly reborn: recent computational challenges}, 
volume = {10}, 
number = {4}, 
pages = {354-366}, 
year = {2009}, 
doi = {10.1093/bib/bbp026}, 
abstract ={Research into genome assembly algorithms has experienced a resurgence due to new challenges created by the development of next generation sequencing technologies. Several genome assemblers have been published in recent years specifically targeted at the new sequence data; however, the ever-changing technological landscape leads to the need for continued research. In addition, the low cost of next generation sequencing data has led to an increased use of sequencing in new settings. For example, the new field of metagenomics relies on large-scale sequencing of entire microbial communities instead of isolate genomes, leading to new computational challenges. In this article, we outline the major algorithmic approaches for genome assembly and describe recent developments in this domain.}, 
URL = {http://bib.oxfordjournals.org/content/10/4/354.abstract}, 
eprint = {http://bib.oxfordjournals.org/content/10/4/354.full.pdf+html}, 
journal = {Briefings in Bioinformatics} 
}

@Article{Phillippy2008,
AUTHOR = {Phillippy, Adam and Schatz, Michael and Pop, Mihai},
TITLE = {Genome assembly forensics: finding the elusive mis-assembly},
JOURNAL = {Genome Biology},
VOLUME = {9},
YEAR = {2008},
NUMBER = {3},
PAGES = {R55},
URL = {http://genomebiology.com/2008/9/3/R55},
DOI = {10.1186/gb-2008-9-3-r55},
PubMedID = {18341692},
ISSN = {1465-6906},
ABSTRACT = {We present the first collection of tools aimed at automated genome assembly validation. This work formalizes several mechanisms for detecting mis-assemblies, and describes their implementation in our automated validation pipeline, called amosvalidate. We demonstrate the application of our pipeline in both bacterial and eukaryotic genome assemblies, and highlight several assembly errors in both draft and finished genomes. The software described is compatible with common assembly formats and is released, open-source, at http://amos.sourceforge.net webcite.},
}

@Article{Perna2001,
author="Perna, Nicole T.
and Plunkett, Guy
and Burland, Valerie
and Mau, Bob
and Glasner, Jeremy D.
and Rose, Debra J.
and Mayhew, George F.
and Evans, Peter S.
and Gregor, Jason
and Kirkpatrick, Heather A.
and Posfai, Gyorgy
and Hackett, Jeremiah
and Klink, Sara
and Boutin, Adam
and Shao, Ying
and Miller, Leslie
and Grotbeck, Erik J.
and Davis, N. Wayne
and Lim, Alex
and Dimalanta, Eileen T.
and Potamousis, Konstantinos D.
and Apodaca, Jennifer
and Anantharaman, Thomas S.
and Lin, Jieyi
and Yen, Galex
and Schwartz, David C.
and Welch, Rodney A.
and Blattner, Frederick R.",
title="Genome sequence of enterohaemorrhagic Escherichia coli O157:H7",
journal="Nature",
year="2001",
month="Jan",
day="25",
volume="409",
number="6819",
pages="529--533",
issn="0028-0836",
doi="10.1038/35054089",
url="http://dx.doi.org/10.1038/35054089"
}

@manual{VelvetOpt,
author = "Seemann, Torsten and Gladman, Simon",
title = "{{VelvetOptimiser}, retrieved from http://bioinformatics.net.au/software.velvetoptimiser.shtml}",
month = "{April}",
year = "{2011}",
url = "{http://bioinformatics.net.au/software.velvetoptimiser.shtml}"
}
