@article{Darling2010,
    author = {Darling, Aaron E. AND Mau, Bob AND Perna, Nicole T.},
    journal = {PLoS ONE},
    publisher = {Public Library of Science},
    title = "{progressiveMauve: Multiple Genome Alignment with Gene Gain, Loss and Rearrangement}",
    year = {2010},
    month = {06},
    volume = {5},
    url = {http://dx.doi.org/10.1371%2Fjournal.pone.0011147},
    pages = {e11147},
    abstract = {<sec>
<title>Background</title>
<p>Multiple genome alignment remains a challenging problem. Effects of recombination including rearrangement, segmental duplication, gain, and loss can create a mosaic pattern of homology even among closely related organisms.</p>
</sec><sec>
<title>Methodology/Principal Findings</title>
<p>We describe a new method to align two or more genomes that have undergone rearrangements due to recombination and substantial amounts of segmental gain and loss (flux). We demonstrate that the new method can accurately align regions conserved in some, but not all, of the genomes, an important case not handled by our previous work. The method uses a novel alignment objective score called a sum-of-pairs breakpoint score, which facilitates accurate detection of rearrangement breakpoints when genomes have unequal gene content. We also apply a probabilistic alignment filtering method to remove erroneous alignments of unrelated sequences, which are commonly observed in other genome alignment methods. We describe new metrics for quantifying genome alignment accuracy which measure the quality of rearrangement breakpoint predictions and indel predictions. The new genome alignment algorithm demonstrates high accuracy in situations where genomes have undergone biologically feasible amounts of genome rearrangement, segmental gain and loss. We apply the new algorithm to a set of 23 genomes from the genera <italic>Escherichia</italic>, <italic>Shigella</italic>, and <italic>Salmonella</italic>. Analysis of whole-genome multiple alignments allows us to extend the previously defined concepts of core- and pan-genomes to include not only annotated genes, but also non-coding regions with potential regulatory roles. The 23 enterobacteria have an estimated core-genome of 2.46Mbp conserved among all taxa and a pan-genome of 15.2Mbp. We document substantial population-level variability among these organisms driven by segmental gain and loss. Interestingly, much variability lies in intergenic regions, suggesting that the Enterobacteriacae may exhibit regulatory divergence.</p>
</sec><sec>
<title>Conclusions</title>
<p>The multiple genome alignments generated by our software provide a platform for comparative genomic and population genomic studies. Free, open-source software implementing the described genome alignment approach is available from <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="http://gel.ahabs.wisc.edu/mauve" xlink:type="simple">http://gel.ahabs.wisc.edu/mauve</ext-link>.</p>
</sec>},
    number = {6},
    doi = {10.1371/journal.pone.0011147}
}        

@article{Earl2011,
author = {Earl, Dent A. and Bradnam, Keith and St. John, John and Darling, Aaron and Lin, Dawei and Faas, Joseph and Yu, Hung On Ken and Vince, Buffalo and Zerbino, Daniel R. and Diekhans, Mark and Nguyen, Ngan and Nuwantha, Pramila and Sung, Ariyaratne Wing-Kin and Ning, Zemin and Haimel, Matthias and Simpson, Jared T. and Fronseca, Nuno A. and Birol, İnanç and Docking, T. Roderick and Ho, Isaac Y. and Rokhsar, Daniel S and Chikhi, Rayan and Lavenier, Dominique and Chapuis, Guillaume and Naquin, Delphine and Maillet, Nicolas and Schatz, Michael C. and Kelly, David R. and Phillippy, Adam M. and Koren, Sergey and Yang, Shiaw-Pyng and Wu, Wei and Chou, Wen-Chi and Srivastava, Anuj and Shaw, Timothy I. and Ruby, J. Graham and Skewes-Cox, Peter and Betegon, Miguel and Dimon, Michelle T. and Solovyev, Victor and Kosarev, Petr and Vorobyev, Denis and Ramirez-Gonzalez, Ricardo and Leggett, Richard and MacLean, Dan and Xia, Fangfang and Luo, Ruibang and L, Zhenyu and Xie, Yinlong and Liu, Binghang and Gnerre, Sante and MacCallum, Iain and Przybylski, Dariusz and Ribeiro, Filipe J. and Yin, Shuangye and Sharpe, Ted and Hall, Giles and Kersey, Paul J. and Durbin, Richard and Jackman, Shaun D. and Chapman, Jarrod A. and Huang, Xiaoqiu and DeRisi, Joseph L. and Caccamo, Mario and Li, Yingrui and Jaffe, David B. and Green, Richard and Haussler, David and Korf, Ian and Paten, Benedict}, 
title = {Assemblathon 1: A competitive assessment of de novo short read assembly methods}, 
year = {2011}, 
doi = {10.1101/gr.126599.111}, 
abstract ={Low cost short read sequencing technology has revolutionised genomics, though it is only just becoming practical for the high quality de novo assembly of a novel large genome. We describe the Assemblathon 1 competition, which aimed to comprehensively assess the state of the art in de novo assembly methods when applied to current sequencing technologies. In a collaborative effort teams were asked to assemble a simulated Illumina HiSeq dataset of an unknown, simulated diploid genome. A total of 41 assemblies from 17 different groups were received. Novel haplotype aware assessments of coverage, contiguity, structure, base calling and copy number were made. We establish that within this benchmark (1) it is possible to assemble the genome to a high level of coverage and accuracy, and that (2) large differences exist between the assemblies, suggesting room for further improvements in current methods.}, 
URL = {http://genome.cshlp.org/content/early/2011/09/16/gr.126599.111.abstract}, 
eprint = {http://genome.cshlp.org/content/early/2011/09/16/gr.126599.111.full.pdf+html}, 
journal = {Genome Research} 
}

@article{Zerbino2008, title={Velvet: algorithms for de novo short read assembly using de Bruijn graphs.}, volume={18}, url={http://www.ncbi.nlm.nih.gov/pubmed/18349386}, number={5}, journal={Genome Research}, publisher={Cold Spring Harbor Lab}, author={Zerbino, Daniel R and Birney, Ewan}, year={2008}, pages={821--9}}

@article{Kozarewa2009, title={Amplification-free Illumina sequencing-library preparation facilitates improved mapping and assembly of (G+C)-biased genomes.}, volume={6}, url={http://www.ncbi.nlm.nih.gov/pubmed/19287394}, number={4}, journal={Nature Methods}, publisher={Nature Publishing Group}, author={Kozarewa, Iwanka and Ning, Zemin and Quail, Michael A and Sanders, Mandy J and Berriman, Matthew and Turner, Daniel J}, year={2009}, pages={291--295}}

@article{Boetzer2011,
author = {Boetzer, Marten and Henkel, Christiaan V. and Jansen, Hans J. and Butler, Derek and Pirovano, Walter}, 
title="{Scaffolding pre-assembled contigs using SSPACE}", 
volume = {27}, 
number = {4}, 
pages = {578-579}, 
year = {2011}, 
doi = {10.1093/bioinformatics/btq683}, 
abstract ={Summary: De novo assembly tools play a main role in reconstructing genomes from next-generation sequencing (NGS) data and usually yield a number of contigs. Using paired-read sequencing data it is possible to assess the order, distance and orientation of contigs and combine them into so-called scaffolds. Although the latter process is a crucial step in finishing genomes, scaffolding algorithms are often built-in functions in de novo assembly tools and cannot be independently controlled. We here present a new tool, called SSPACE, which is a stand-alone scaffolder of pre-assembled contigs using paired-read data. Main features are: a short runtime, multiple library input of paired-end and/or mate pair datasets and possible contig extension with unmapped sequence reads. SSPACE shows promising results on both prokaryote and eukaryote genomic testsets where the amount of initial contigs was reduced by at least 75%.Availability: www.baseclear.com/bioinformatics-tools/.Contact: walter.pirovano@baseclear.comSupplementary information: Supplementary data are available at Bioinformatics online.}, 
URL = {http://bioinformatics.oxfordjournals.org/content/27/4/578.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/27/4/578.full.pdf+html}, 
journal = {Bioinformatics} 
}

@article{Simpson2010,
author = {Simpson, Jared T. and Durbin, Richard}, 
title = {Efficient construction of an assembly string graph using the FM-index}, 
volume = {26}, 
number = {12}, 
pages = {i367-i373}, 
year = {2010}, 
doi = {10.1093/bioinformatics/btq217}, 
abstract ={Motivation: Sequence assembly is a difficult problem whose importance has grown again recently as the cost of sequencing has dramatically dropped. Most new sequence assembly software has started by building a de Bruijn graph, avoiding the overlap-based methods used previously because of the computational cost and complexity of these with very large numbers of short reads. Here, we show how to use suffix array-based methods that have formed the basis of recent very fast sequence mapping algorithms to find overlaps and generate assembly string graphs asymptotically faster than previously described algorithms.Results: Standard overlap assembly methods have time complexity O(N2), where N is the sum of the lengths of the reads. We use the Ferragina–Manzini index (FM-index) derived from the Burrows–Wheeler transform to find overlaps of length at least τ among a set of reads. As well as an approach that finds all overlaps then implements transitive reduction to produce a string graph, we show how to output directly only the irreducible overlaps, significantly shrinking memory requirements and reducing compute time to O(N), independent of depth. Overlap-based assembly methods naturally handle mixed length read sets, including capillary reads or long reads promised by the third generation sequencing technologies. The algorithms we present here pave the way for overlap-based assembly approaches to be developed that scale to whole vertebrate genome de novo assembly.Contact: js18@sanger.ac.uk}, 
URL = {http://bioinformatics.oxfordjournals.org/content/26/12/i367.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/26/12/i367.full.pdf+html}, 
journal = {Bioinformatics} 
}

@article{Peng2010, title={IDBA - A Practical Iterative de Bruijn Graph De Novo Assembler}, volume={6044}, url={http://www.springerlink.com/index/622866948LH233G7.pdf}, journal={Computer}, publisher={Springer}, author={Peng, Yu and Leung, Henry and Yiu, S M and Chin, Francis Y L}, year={2010}, pages={426--440}}

@article{Lassmann2009,
author = {Lassmann, Timo and Hayashizaki, Yoshihide and Daub, Carsten O.}, 
title = {TagDust—a program to eliminate artifacts from next generation sequencing data}, 
volume = {25}, 
number = {21}, 
pages = {2839-2840}, 
year = {2009}, 
doi = {10.1093/bioinformatics/btp527}, 
abstract ={Motivation: Next-generation parallel sequencing technologies produce large quantities of short sequence reads. Due to experimental procedures various types of artifacts are commonly sequenced alongside the targeted RNA or DNA sequences. Identification of such artifacts is important during the development of novel sequencing assays and for the downstream analysis of the sequenced libraries.Results: Here we present TagDust, a program identifying artifactual sequences in large sequencing runs. Given a user-defined cutoff for the false discovery rate, TagDust identifies all reads explainable by combinations and partial matches to known sequences used during library preparation. We demonstrate the quality of our method on sequencing runs performed on Illumina's Genome Analyzer platform.Availability: Executables and documentation are available from http://genome.gsc.riken.jp/osc/english/software/.Contact: timolassmann@gmail.com}, 
URL = {http://bioinformatics.oxfordjournals.org/content/25/21/2839.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/25/21/2839.full.pdf+html}, 
journal = {Bioinformatics} 
}

@article{Yang2010,
author = {Yang, Xiao and Dorman, Karin S. and Aluru, Srinivas}, 
title="{Reptile: representative tiling for short read error correction}", 
volume = {26}, 
number = {20}, 
pages = {2526-2533}, 
year = {2010}, 
doi = {10.1093/bioinformatics/btq468}, 
abstract ={Motivation: Error correction is critical to the success of next-generation sequencing applications, such as resequencing and de novo genome sequencing. It is especially important for high-throughput short-read sequencing, where reads are much shorter and more abundant, and errors more frequent than in traditional Sanger sequencing. Processing massive numbers of short reads with existing error correction methods is both compute and memory intensive, yet the results are far from satisfactory when applied to real datasets.Results: We present a novel approach, termed Reptile, for error correction in short-read data from next-generation sequencing. Reptile works with the spectrum of k-mers from the input reads, and corrects errors by simultaneously examining: (i) Hamming distance-based correction possibilities for potentially erroneous k-mers; and (ii) neighboring k-mers from the same read for correct contextual information. By not needing to store input data, Reptile has the favorable property that it can handle data that does not fit in main memory. In addition to sequence data, Reptile can make use of available quality score information. Our experiments show that Reptile outperforms previous methods in the percentage of errors removed from the data and the accuracy in true base assignment. In addition, a significant reduction in run time and memory usage have been achieved compared with previous methods, making it more practical for short-read error correction when sampling larger genomes.Availability: Reptile is implemented in C++ and is available through the link: http://aluru-sun.ece.iastate.edu/doku.php?id=softwareContact: aluru@iastate.edu}, 
URL = {http://bioinformatics.oxfordjournals.org/content/26/20/2526.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/26/20/2526.full.pdf+html}, 
journal = {Bioinformatics} 
}
@article{Hartman2010,
     author = {Hartman, Amber L. AND Norais, Cédric AND Badger, Jonathan H. AND Delmas, Stéphane AND Haldenby, Sam AND Madupu, Ramana AND Robinson, Jeffrey AND Khouri, Hoda AND Ren, Qinghu AND Lowe, Todd M. AND Maupin-Furlow, Julie AND Pohlschroder, Mecky AND Daniels, Charles AND Pfeiffer, Friedhelm AND Allers, Thorsten AND Eisen, Jonathan A.},
    journal = {PLoS ONE},
    publisher = {Public Library of Science},
    title = "{The Complete Genome Sequence of \textit{Haloferax volcanii} DS2, a Model Archaeon}",
    year = {2010},
    month = {03},
    volume = {5},
    url = {http://dx.doi.org/10.1371%2Fjournal.pone.0009605},
    pages = {e9605},
    abstract = {<sec>
<title>Background</title>
<p><italic>Haloferax volcanii</italic> is an easily culturable moderate halophile that grows on simple defined media, is readily transformable, and has a relatively stable genome. This, in combination with its biochemical and genetic tractability, has made <italic>Hfx. volcanii</italic> a key model organism, not only for the study of halophilicity, but also for archaeal biology in general.</p>
</sec><sec>
<title>Methodology/Principal Findings</title>
<p>We report here the sequencing and analysis of the genome of <italic>Hfx. volcanii</italic> DS2, the type strain of this species. The genome contains a main 2.848 Mb chromosome, three smaller chromosomes pHV1, 3, 4 (85, 438, 636 kb, respectively) and the pHV2 plasmid (6.4 kb).</p>
</sec><sec>
<title>Conclusions/Significance</title>
<p>The completed genome sequence, presented here, provides an invaluable tool for further <italic>in vivo</italic> and <italic>in vitro</italic> studies of <italic>Hfx. volcanii</italic>.</p>
</sec>},
    number = {3},
    doi = {10.1371/journal.pone.0009605}
}        

﻿@article {Phillippy2008,
   author = {Phillippy, Adam and Schatz, Michael and Pop, Mihai},
   affiliation = {Center for Bioinformatics and Computational Biology, University of Maryland, College Park, MD 20742, USA},
title="{Genome assembly forensics: finding the elusive mis-assembly}",
   journal = {Genome Biology},
   publisher = {BioMed Central},
   issn = {},
   keyword = {Human Genetics},
   pages = {1-13},
   volume = {9},
   issue = {3},
   url = {http://dx.doi.org/10.1186/gb-2008-9-3-r55},
   note = {10.1186/gb-2008-9-3-r55},
   year = {2008}
}

@article{Treangen2006,
    author = {Treangen, Todd  J.  and Messeguer, Xavier  },
    citeulike-article-id = {885153},
    doi = {10.1186/1471-2105-7-433},
    issn = {1471-2105},
    journal = {BMC Bioinformatics},
    keywords = {alignment genomecomparison genomerearrangement},
    month = {October},
    pages = {433+},
    priority = {2},
    title = "{M-GCAT: Interactively and efficiently constructing large-scale multiple genome comparison frameworks in closely related species}",
    url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve\&db=pubmed\&dopt=Abstract\&list_uids=17022809},
    volume = {7},
    year = {2006}
}

@ARTICLE{mauve,
author = "Darling, Aaron C E and Mau, Bob and Blattner, Frederick R  and Perna, Nicole T",
journal = "Genome Res",
pages = "1394--403",
title = "{Mauve: multiple alignment of conserved genomic sequence with rearrangements}",
volume = "14",
number = "7",
year = 2004,
}


@article{Yancopoulos2005,
    abstract = {MOTIVATION: Finding genomic distance based on gene order is a classic problem in genome rearrangements. Efficient exact algorithms for genomic distances based on inversions and/or translocations have been found but are complicated by special cases, rare in simulations and empirical data. We seek a universal operation underlying a more inclusive set of evolutionary operations and yielding a tractable genomic distance with simple mathematical form. RESULTS: We study a universal double-cut-and-join operation that accounts for inversions, translocations, fissions and fusions, but also produces circular intermediates which can be reabsorbed. The genomic distance, computable in linear time, is given by the number of breakpoints minus the number of cycles (b-c) in the comparison graph of the two genomes; the number of hurdles does not enter into it. Without changing the formula, we can replace generation and re-absorption of a circular intermediate by a generalized transposition, equivalent to a block interchange, with weight two. Our simple algorithm converts one multi-linear chromosome genome to another in the minimum distance.},
    address = {The Feinstein Institute for Medical Research North Shore-LIJ Health System, Manhasset, NY 11030, USA. syancopo@nshs.edu},
    author = {Yancopoulos, S.  and Attie, O.  and Friedberg, R. },
    citeulike-article-id = {735705},
    issn = {1367-4803},
    journal = {Bioinformatics},
    keywords = {genomerearrangement},
    month = {August},
    number = {16},
    pages = {3340--3346},
    priority = {2},
title="{Efficient sorting of genomic permutations by translocation, inversion and block interchange}",
    url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve\&db=pubmed\&dopt=Abstract\&list_uids=15951307},
    volume = {21},
    year = {2005}
}

@inproceedings{Bergeron2006,
   author = {Bergeron, A. and Mixtacki, J. and Stoye, J.},
title="{A Unifying View of Genome Rearrangements}",
  booktitle = {WABI '06: Proceedings of the Sixth International Workshop on Algorithms in Bioinformatics},
  series    = {Lecture Notes in Computer Science},
  volume    = {4175},
  year      = {2006},
  pages     = {163-173},
  ee        = {http://dx.doi.org/10.1007/11851561_16},
  crossref  = {DBLP:conf/wabi/2006},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@proceedings{DBLP:conf/wabi/2006,
  editor    = {Philipp Bucher and
               Bernard M. E. Moret},
  title     = {Algorithms in Bioinformatics, 6th International Workshop,
               WABI 2006, Zurich, Switzerland, September 11-13, 2006, Proceedings},
  booktitle = {WABI},
  publisher = {Springer},
  series    = {Lecture Notes in Computer Science},
  volume    = {4175},
  year      = {2006},
  isbn      = {3-540-39583-0},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}


@article{BLAST,
author = {Altschul, Stephen F. and Madden, Thomas L. and Schäffer, Alejandro A. and Zhang, Jinghui and Zhang, Zheng and Miller, Webb and Lipman, David J.}, 
title = "{Gapped BLAST and PSI-BLAST: a new generation of protein database search programs}", 
volume = {25}, 
number = {17}, 
pages = {3389-3402}, 
year = {1997}, 
doi = {10.1093/nar/25.17.3389}, 
abstract ={The BLAST programs are widely used tools for searching protein and DNA databases for sequence similarities. For protein comparisons, a variety of definitional, algorithmic and statistical refinements described here permits the execution time of the BLAST programs to be decreased substantially while enhancing their sensitivity to weak similarities. A new criterion for triggering the extension of word hits, combined with a new heuristic for generating gapped alignments, yields a gapped BLAST program that runs at approximately three times the speed of the original. In addition, a method is introduced for automatically combining statistically significant alignments produced by BLAST into a position-specific score matrix, and searching the database using this matrix. The resulting Position-Specific Iterated BLAST (PSIBLAST) program runs at approximately the same speed per iteration as gapped BLAST, but in many cases is much more sensitive to weak but biologically relevant sequence similarities. PSI-BLAST is used to uncover several new and interesting members of the BRCT superfamily.}, 
URL = {http://nar.oxfordjournals.org/content/25/17/3389.abstract}, 
eprint = {http://nar.oxfordjournals.org/content/25/17/3389.full.pdf+html}, 
journal = {Nucleic Acids Research} 
}

@Article{bowtie,
AUTHOR = {Langmead, Ben and Trapnell, Cole and Pop, Mihai and Salzberg, Steven},
TITLE = {Ultrafast and memory-efficient alignment of short DNA sequences to the human genome},
JOURNAL = {Genome Biology},
VOLUME = {10},
YEAR = {2009},
NUMBER = {3},
PAGES = {R25},
URL = {http://genomebiology.com/2009/10/3/R25},
DOI = {10.1186/gb-2009-10-3-r25},
PubMedID = {19261174},
ISSN = {1465-6906},
ABSTRACT = {
            Bowtie is an ultrafast, memory-efficient alignment program for aligning short DNA sequence reads to large genomes. For the human genome, Burrows-Wheeler indexing allows Bowtie to align more than 25 million reads per CPU hour with a memory footprint of approximately 1.3 gigabytes. Bowtie extends previous Burrows-Wheeler techniques with a novel quality-aware backtracking algorithm that permits mismatches. Multiple processor cores can be used simultaneously to achieve even greater alignment speeds. Bowtie is open source http://bowtie.cbcb.umd.edu webcite.
      },
}
@article{bwa,
author = {Li, Heng and Durbin, Richard}, 
title="{Fast and accurate short read alignment with Burrows–Wheeler transform}", 
volume = {25}, 
number = {14}, 
pages = {1754-1760}, 
year = {2009}, 
doi = {10.1093/bioinformatics/btp324}, 
abstract ={Motivation: The enormous amount of short reads generated by the new DNA sequencing technologies call for the development of fast and accurate read alignment programs. A first generation of hash table-based methods has been developed, including MAQ, which is accurate, feature rich and fast enough to align short reads from a single individual. However, MAQ does not support gapped alignment for single-end reads, which makes it unsuitable for alignment of longer reads where indels may occur frequently. The speed of MAQ is also a concern when the alignment is scaled up to the resequencing of hundreds of individuals.Results: We implemented Burrows-Wheeler Alignment tool (BWA), a new read alignment package that is based on backward search with Burrows–Wheeler Transform (BWT), to efficiently align short sequencing reads against a large reference sequence such as the human genome, allowing mismatches and gaps. BWA supports both base space reads, e.g. from Illumina sequencing machines, and color space reads from AB SOLiD machines. Evaluations on both simulated and real data suggest that BWA is ∼10–20× faster than MAQ, while achieving similar accuracy. In addition, BWA outputs alignment in the new standard SAM (Sequence Alignment/Map) format. Variant calling and other downstream analyses after the alignment can be achieved with the open source SAMtools software package.Availability: http://maq.sourceforge.netContact: rd@sanger.ac.uk}, 
URL = {http://bioinformatics.oxfordjournals.org/content/25/14/1754.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/25/14/1754.full.pdf+html}, 
journal = {Bioinformatics} 
}


@article{Rissman2009,
author = {Rissman, Anna I. and Mau, Bob and Biehl, Bryan S. and Darling, Aaron E. and Glasner, Jeremy D. and Perna, Nicole T.}, 
title = "{Reordering contigs of draft genomes using the Mauve Aligner}", 
volume = {25}, 
number = {16}, 
pages = {2071-2073}, 
year = {2009}, 
doi = {10.1093/bioinformatics/btp356}, 
abstract ={Summary: Mauve Contig Mover provides a new method for proposing the relative order of contigs that make up a draft genome based on comparison to a complete or draft reference genome. A novel application of the Mauve aligner and viewer provides an automated reordering algorithm coupled with a powerful drill-down display allowing detailed exploration of results.Availability: The software is available for download at http://gel.ahabs.wisc.edu/mauve.Contact: rissman@wisc.eduSupplementary information: Supplementary data are available at Bioinformatics online and http://gel.ahabs.wisc.edu}, 
URL = {http://bioinformatics.oxfordjournals.org/content/25/16/2071.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/25/16/2071.full.pdf+html}, 
journal = {Bioinformatics} 
}

@article{Li2010,
author = {Li, Ruiqiang and Zhu, Hongmei and Ruan, Jue and Qian, Wubin and Fang, Xiaodong and Shi, Zhongbin and Li, Yingrui and Li, Shengting and Shan, Gao and Kristiansen, Karsten and Li, Songgang and Yang, Huanming and Wang, Jian and Wang, Jun}, 
title = {De novo assembly of human genomes with massively parallel short read sequencing}, 
volume = {20}, 
number = {2}, 
pages = {265-272}, 
year = {2010}, 
doi = {10.1101/gr.097261.109}, 
abstract ={Next-generation massively parallel DNA sequencing technologies provide ultrahigh throughput at a substantially lower unit data cost; however, the data are very short read length sequences, making de novo assembly extremely challenging. Here, we describe a novel method for de novo assembly of large genomes from short read sequences. We successfully assembled both the Asian and African human genome sequences, achieving an N50 contig size of 7.4 and 5.9 kilobases (kb) and scaffold of 446.3 and 61.9 kb, respectively. The development of this de novo short read assembly method creates new opportunities for building reference sequences and carrying out accurate analyses of unexplored genomes in a cost-effective way.}, 
URL = {http://genome.cshlp.org/content/20/2/265.abstract}, 
eprint = {http://genome.cshlp.org/content/20/2/265.full.pdf+html}, 
journal = {Genome Research} 
}

@manual{SASSY,
author = {Imelfort, Michael},
title = {The {SaSSY} manual, retrieved from {https://github.com/minillinim/SaSSY/blob/master/SaSSY\_manual.pdf}},
month = {June},
year = {2011},
url = {https://github.com/minillinim/SaSSY/blob/master/SaSSY_manual.pdf}
}

@article{Gnerre2011,
author = {Gnerre, Sante and MacCallum, Iain and Przybylski, Dariusz and Ribeiro, Filipe J. and Burton, Joshua N. and Walker, Bruce J. and Sharpe, Ted and Hall, Giles and Shea, Terrance P. and Sykes, Sean and Berlin, Aaron M. and Aird, Daniel and Costello, Maura and Daza, Riza and Williams, Louise and Nicol, Robert and Gnirke, Andreas and Nusbaum, Chad and Lander, Eric S. and Jaffe, David B.}, 
title = {High-quality draft assemblies of mammalian genomes from massively parallel sequence data}, 
volume = {108}, 
number = {4}, 
pages = {1513-1518}, 
year = {2011}, 
doi = {10.1073/pnas.1017351108}, 
abstract ={Massively parallel DNA sequencing technologies are revolutionizing genomics by making it possible to generate billions of relatively short (~100-base) sequence reads at very low cost. Whereas such data can be readily used for a wide range of biomedical applications, it has proven difficult to use them to generate high-quality de novo genome assemblies of large, repeat-rich vertebrate genomes. To date, the genome assemblies generated from such data have fallen far short of those obtained with the older (but much more expensive) capillary-based sequencing approach. Here, we report the development of an algorithm for genome assembly, ALLPATHS-LG, and its application to massively parallel DNA sequence data from the human and mouse genomes, generated on the Illumina platform. The resulting draft genome assemblies have good accuracy, short-range contiguity, long-range connectivity, and coverage of the genome. In particular, the base accuracy is high (≥99.95%) and the scaffold sizes (N50 size = 11.5 Mb for human and 7.2 Mb for mouse) approach those obtained with capillary-based sequencing. The combination of improved sequencing technology and improved computational methods should now make it possible to increase dramatically the de novo sequencing of large genomes. The ALLPATHS-LG program is available at http://www.broadinstitute.org/science/programs/genome-biology/crd.}, 
URL = {http://www.pnas.org/content/108/4/1513.abstract}, 
eprint = {http://www.pnas.org/content/108/4/1513.full.pdf+html}, 
journal = {Proceedings of the National Academy of Sciences} 
}
@article{Li01032008,
author = {Li, Ruiqiang and Li, Yingrui and Kristiansen, Karsten and Wang, Jun}, 
title = {SOAP: short oligonucleotide alignment program}, 
volume = {24}, 
number = {5}, 
pages = {713-714}, 
year = {2008}, 
doi = {10.1093/bioinformatics/btn025}, 
abstract ={Summary: We have developed a program SOAP for efficient gapped and ungapped alignment of short oligonucleotides onto reference sequences. The program is designed to handle the huge amounts of short reads generated by parallel sequencing using the new generation Illumina-Solexa sequencing technology. SOAP is compatible with numerous applications, including single-read or pair-end resequencing, small RNA discovery and mRNA tag sequence mapping. SOAP is a command-driven program, which supports multi-threaded parallel computing, and has a batch module for multiple query sets.Availability: http://soap.genomics.org.cnContact: soap@genomics.org.cn}, 
URL = {http://bioinformatics.oxfordjournals.org/content/24/5/713.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/24/5/713.full.pdf+html}, 
journal = {Bioinformatics} 
}
@article{Darling2011,
author = {Darling, Aaron and Tritt, Andrew and Eisen, Jonathan A. and Facciotti, Marc T.}, 
title = {Mauve Assembly Metrics}, 
year = {2011}, 
doi = {10.1093/bioinformatics/btr451}, 
abstract ={Summary: High throughput DNA sequencing technologies have spurred the development of numerous novel methods for genome assembly. With few exceptions, these algorithms are heuristic and require one or more parameters to be manually set by the user. One approach to parameter tuning involves assembling data from an organism with an available high quality reference genome, and measuring assembly accuracy using some metrics.We developed a system to measure assembly quality under several scoring metrics, and to compare assembly quality across a variety of assemblers, sequence data types, and parameter choices. When used in conjunction with training data such as a high quality reference genome and sequence reads from the same organism, our program can be used to manually identify an optimal sequencing and assembly strategy for de novo sequencing of related organisms.Availability: GPL source code and a usage tutorial is at http://ngopt.googlecode.comContact: aarondarling@ucdavis.edu}, 
URL = {http://bioinformatics.oxfordjournals.org/content/early/2011/08/02/bioinformatics.btr451.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/early/2011/08/02/bioinformatics.btr451.full.pdf+html}, 
journal = {Bioinformatics} 
}
@Article{Adey2010,
AUTHOR = {Adey, Andrew and Morrison, Hilary and Asan and Xun, Xu and Kitzman, Jacob and Turner, Emily and Stackhouse, Bethany and MacKenzie, Alexandra and Caruccio, Nicholas and Zhang, Xiuqing and Shendure, Jay},
TITLE = {Rapid, low-input, low-bias construction of shotgun fragment libraries by high-density in vitro transposition},
JOURNAL = {Genome Biology},
VOLUME = {11},
YEAR = {2010},
NUMBER = {12},
PAGES = {R119},
URL = {http://genomebiology.com/content/11/12/R119},
DOI = {10.1186/gb-2010-11-12-r119},
PubMedID = {21143862},
ISSN = {1465-6906},
ABSTRACT = {We characterize and extend a highly efficient method for constructing shotgun fragment libraries in which transposase catalyzes in vitro DNA fragmentation and adaptor incorporation simultaneously. We apply this method to sequencing a human genome and find that coverage biases are comparable to those of conventional protocols. We also extend its capabilities by developing protocols for sub-nanogram library construction, exome capture from 50 ng of input DNA, PCR-free and colony PCR library construction, and 96-plex sample indexing.},
}
@article{DBSCAN, 
title={A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise}, 
volume={96}, url={http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:A+Density-Based+Algorithm+for+Discovering+Clusters+in+Large+Spatial+Databases+with+Noise#0}, 
journal={Computer}, 
publisher={AAAI Press}, 
author={Ester, Martin and Kriegel, Hans-Peter and Sander, Jörg and Xu, Xiaowei}, 
year={1996},
pages={226–231}}

@article{GuptaChen2010,
  author    = {Maya R. Gupta and
               Yihua Chen},
  title     = {Theory and Use of the EM Algorithm},
  journal   = {Foundations and Trends in Signal Processing},
  volume    = {4},
  number    = {3},
  year      = {2010},
  pages     = {223-296},
  ee        = {http://dx.doi.org/10.1561/2000000034},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

